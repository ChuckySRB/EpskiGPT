{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Токенизација\n",
    "\n",
    "> Токенизација је процес представљања сирових података у виду токена (најчеће бајтови података)\n",
    "\n",
    "Од квалитета токена доста зависи и учинак самог модела\n",
    "Токен је најмањи вид податка коме модел даје значење, и пошто их може бити ограничен број, јер цена модела расте значајно са повећањем самог вокабулара, избор величине токена и шта тај токен треба да обухвати је доста тежак задатак, и мале одлуке доста могу утицати на то шта ће модел разумети из података. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизација текста\n",
    "\n",
    "Код токенизације текста, најчешће се текст у виду стрига прво претвори у бајтове помоћу utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здраво b'\\xd0\\x97\\xd0\\xb4\\xd1\\x80\\xd0\\xb0\\xd0\\xb2\\xd0\\xbe'\n",
      "6 12\n"
     ]
    }
   ],
   "source": [
    "text = \"Здраво\" \n",
    "text_bytes = text.encode(\"utf-8\")\n",
    "\n",
    "print(text, text_bytes)\n",
    "print(len(text), len(text_bytes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Међутим овде настаје проблем, пошто је utf-8 погодан само за латинична слова, __ћирилица__ се претвори у 2 бајта и због алгоритма који користимо за спајање токена, број токена које будемо генерисали ће бити дупло већи и сами токени ће бити мање ефикасни\n",
    "\n",
    "- Због овог разлога ћемо користити сам текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здраво [1047, 1076, 1088, 1072, 1074, 1086]\n",
      "6 6\n"
     ]
    }
   ],
   "source": [
    "text = \"Здраво\"\n",
    "text_ints = [ord(s) for s in text]\n",
    "\n",
    "print (text, text_ints)\n",
    "print (len(text), len(text_ints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte-Pair Encoding\n",
    "\n",
    "Овај алгоритам и две методе које се понављају\n",
    "\n",
    "1. Пронађи два суседна слова која се понављају најчешће\n",
    "\n",
    "2. Замини да два пара са новим токеном\n",
    "\n",
    "Ове две методе се понављају над текстом за тренинг токенизера док се не добије жељени број токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'â', 14: 'ê', 15: 'ô', 16: '̓', 17: 'Ђ', 18: 'Ј', 19: 'Љ', 20: 'Њ', 21: 'Ћ', 22: 'Џ', 23: 'А', 24: 'Б', 25: 'В', 26: 'Г', 27: 'Д', 28: 'Е', 29: 'Ж', 30: 'З', 31: 'И', 32: 'К', 33: 'Л', 34: 'М', 35: 'Н', 36: 'О', 37: 'П', 38: 'Р', 39: 'С', 40: 'Т', 41: 'У', 42: 'Ф', 43: 'Х', 44: 'Ц', 45: 'Ч', 46: 'Ш', 47: 'а', 48: 'б', 49: 'в', 50: 'г', 51: 'д', 52: 'е', 53: 'ж', 54: 'з', 55: 'и', 56: 'к', 57: 'л', 58: 'м', 59: 'н', 60: 'о', 61: 'п', 62: 'р', 63: 'с', 64: 'т', 65: 'у', 66: 'ф', 67: 'х', 68: 'ц', 69: 'ч', 70: 'ш', 71: 'ђ', 72: 'ј', 73: 'љ', 74: 'њ', 75: 'ћ', 76: 'џ', 77: '–', 78: '—', 79: '’', 80: '“', 81: '”', 82: '„'}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {} # Вокабулар (int) -> ('char')\n",
    "\n",
    "INPUT_FILE = \"D:\\Caslav\\Poso\\AI\\EpskiGPT\\data\\\\narodne_pesme.txt\"\n",
    "\n",
    "# Функција за учитавањње почетног скупа знакова\n",
    "def create_vocabulary(text: str):\n",
    "    chars = sorted(list(set(text)))\n",
    "    vocab = { i:ch for i,ch in enumerate(chars) }\n",
    "    return vocab\n",
    "\n",
    "# Отварање фајла из ког вадимо текст\n",
    "with open(INPUT_FILE, \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "vocabulary = create_vocabulary(text)\n",
    "\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2): 4, (2, 3): 1, (3, 1): 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поделићемо тренирање Токенајзера у неколико корака\n",
    "\n",
    "# Помоћна функција која броји понаљање узастопних токена\n",
    "def count_conseq_tokens(ids, counts={}):\n",
    "    \"\"\"\n",
    "    За дату листу интиџера, врати речник броја понављања узаступних парова\n",
    "    Пример: [1, 2, 3, 1, 2] -> {(1, 2): 2, (2, 3): 1, (3, 1): 1}\n",
    "    Опционо ажурира већ дата пребројавања\n",
    "    \"\"\"\n",
    "    for pair in zip(ids[:-1], ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "count_conseq_tokens([1, 2, 3, 1, 2], {(1, 2): 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функција која обацује нове токене у текст\n",
    "def merge(ids, pair, idx):\n",
    "    \"\"\"\n",
    "    Замени све парове pair који се појављују у ids листи са idx\n",
    "    Пример: ids=[1, 2, 3, 1, 2], pair=(1, 2), idx=4 -> [4, 3, 4]\n",
    "    \"\"\"\n",
    "    new_ids = []\n",
    "    i = 0\n",
    "    ids_n = len(ids)\n",
    "    while i < ids_n-1:\n",
    "        if (ids[i], ids[i+1]) == pair:\n",
    "            new_ids.append(idx)\n",
    "            i+=1\n",
    "        else:\n",
    "            new_ids.append(ids[i])\n",
    "        i+=1\n",
    "    \n",
    "    return new_ids\n",
    "\n",
    "merge([1, 2, 3, 1, 2], (1, 2), 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
